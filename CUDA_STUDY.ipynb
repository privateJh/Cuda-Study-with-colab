{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CUDA_STUDY.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "XcKr7nZ2NKjP",
        "-5WTHHFKfDsy",
        "4LrVfrPBfayF"
      ],
      "authorship_tag": "ABX9TyMlM00AVPEVBqwFAKPne9TX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/privateJh/Cuda-Study-with-colab/blob/main/CUDA_STUDY.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdIptSatMOTG"
      },
      "source": [
        "# **GPU 연결 확인**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxCb2x80nPxY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "460fafb6-dd64-453e-fec5-c6a57702df39"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVzvMzV5duP6",
        "outputId": "a95ae347-46d1-4d86-92a0-0fd0fc989f65"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head /proc/cpuinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mf3Cd1aLooAP",
        "outputId": "4f2f04c6-26cd-40aa-ef34-717aeeac25dc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processor\t: 0\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 63\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0x1\n",
            "cpu MHz\t\t: 2299.998\n",
            "cache size\t: 46080 KB\n",
            "physical id\t: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWmdAvNbdyFr",
        "outputId": "1b5c16ed-8a1e-4c16-87e0-ea1025c6abe4"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Dec 23 04:53:16 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8    28W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPKM6sFI4fRt",
        "outputId": "b58a323c-7b0c-461b-f566-1c4ffb5e24da"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jpe9OtWdMho3"
      },
      "source": [
        "# **GIT 으로 NVCC Jupyter  다운로드**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSqHxfyw5T-_",
        "outputId": "54efb4d5-1b44-4389-d4b4-b8d97c4f7aa5"
      },
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-c45xwxhy\n",
            "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-c45xwxhy\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4305 sha256=1e043fa82f149a3f6e2a893527d06e04064284bc92ce02b54592c9d259d5db63\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-01sb3icb/wheels/c5/2b/c0/87008e795a14bbcdfc7c846a00d06981916331eb980b6c8bdf\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHSZOiS95Ygz",
        "outputId": "89767499-eb20-474a-a496-0ed77486bc02"
      },
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLUkyHlJ5dJq",
        "outputId": "32fa516a-43bd-43d4-9754-9f8eaa1ba632"
      },
      "source": [
        "%cd /usr/local"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMSaFIO55y71",
        "outputId": "22a722f2-0ecc-4f3a-c146-d36b73883744"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTGzK6NH5_Ff",
        "outputId": "8ffffe38-b703-4f7b-98ed-54fa9565f531"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bin\t   cuda-11    games\t\t  LICENSE.txt  setup.cfg\n",
            "cuda\t   cuda-11.0  _gcs_config_ops.so  licensing    share\n",
            "cuda-10.0  cuda-11.1  include\t\t  man\t       src\n",
            "cuda-10.1  etc\t      lib\t\t  sbin\t       xgboost\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hea6g_XzM0eD"
      },
      "source": [
        "# **CUDA 11버전 지우고 10버전 사용**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ESqdoko6FiP"
      },
      "source": [
        "!rm -rf cuda"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmFUM7sI6IrF"
      },
      "source": [
        "!ln -s /usr/local/cuda-10.1 /usr/local/cuda"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLQOewn66LaS",
        "outputId": "654f511f-c840-4b98-a7ca-5791b53da411"
      },
      "source": [
        "!stat cuda"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  File: cuda -> /usr/local/cuda-10.1\n",
            "  Size: 20        \tBlocks: 0          IO Block: 4096   symbolic link\n",
            "Device: 24h/36d\tInode: 4325382     Links: 1\n",
            "Access: (0777/lrwxrwxrwx)  Uid: (    0/    root)   Gid: (    0/    root)\n",
            "Access: 2021-12-23 04:53:53.521365179 +0000\n",
            "Modify: 2021-12-23 04:53:49.425382333 +0000\n",
            "Change: 2021-12-23 04:53:49.425382333 +0000\n",
            " Birth: -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcKr7nZ2NKjP"
      },
      "source": [
        "# **예시 프로그램**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TR7C-zTa6qp4",
        "outputId": "8a797d0c-3ae5-4491-d765-512e2ccbfa31"
      },
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "__global__ void add(int *a, int *b, int *c) {\n",
        "*c = *a + *b;\n",
        "}\n",
        "int main() {\n",
        "int a, b, c;\n",
        "// host copies of variables a, b & c\n",
        "int *d_a, *d_b, *d_c;\n",
        "// device copies of variables a, b & c\n",
        "int size = sizeof(int);\n",
        "// Allocate space for device copies of a, b, c\n",
        "cudaMalloc((void **)&d_a, size);\n",
        "cudaMalloc((void **)&d_b, size);\n",
        "cudaMalloc((void **)&d_c, size);\n",
        "// Setup input values  \n",
        "c = 0;\n",
        "a = 3;\n",
        "b = 5;\n",
        "// Copy inputs to device\n",
        "cudaMemcpy(d_a, &a, size, cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(d_b, &b, size, cudaMemcpyHostToDevice);\n",
        "// Launch add() kernel on GPU\n",
        "add<<<1,1>>>(d_a, d_b, d_c);\n",
        "// Copy result back to host\n",
        "cudaError err = cudaMemcpy(&c, d_c, size, cudaMemcpyDeviceToHost);\n",
        "  if(err!=cudaSuccess) {\n",
        "      printf(\"CUDA error copying to Host: %s\\n\", cudaGetErrorString(err));\n",
        "  }\n",
        "printf(\"result is %d\\n\",c);\n",
        "// Cleanup\n",
        "cudaFree(d_a);\n",
        "cudaFree(d_b);\n",
        "cudaFree(d_c);\n",
        "return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "result is 8\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvoG7qukd422",
        "outputId": "79c90a3b-c2f3-436d-d875-d48358e30d97"
      },
      "source": [
        "%%cu\n",
        "\n",
        "# include <stdio.h>\n",
        " \n",
        "__global__ void helloCUDA(void)\n",
        "{\n",
        "    printf(\"Hello CUDA from GPU! \\n\");\n",
        "}\n",
        " \n",
        "int main(void)\n",
        "{\n",
        "  helloCUDA<<<1, 1>>>();\n",
        "  printf(\"Hello CUDA! \\n\");\n",
        "  cudaDeviceReset();\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello CUDA! \n",
            "Hello CUDA from GPU! \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TBGht4M8EPY",
        "outputId": "712c3369-c08b-4512-a284-0bbafd0e93e4"
      },
      "source": [
        "%%cu\n",
        "#include <iostream>\n",
        "int main(){\n",
        "    std::cout << \"hello world\"<<std::endl;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello world\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGAm93atoHua",
        "outputId": "1187ef2b-b317-4a19-b440-e3c366e7fe6b"
      },
      "source": [
        "%%cu\n",
        "\n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"device_launch_parameters.h\"\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <string.h>\n",
        "\n",
        "// The size of the vector\n",
        "#define NUM_DATA 512\n",
        "\n",
        "// Simple vector sum kernel (Max vector size : 1024)\n",
        "__global__ void vecAdd(int *_a, int *_b, int *_c) {\n",
        "\tint tID = threadIdx.x;\n",
        "\t_c[tID] = _a[tID] + _b[tID];\n",
        "}\n",
        "\n",
        "int main(void)\n",
        "{\n",
        "\n",
        "\tint *a, *b, *c;\t// Vectors on the host\n",
        "\tint *d_a, *d_b, *d_c;\t// Vectors on the device\n",
        "\n",
        "\tint memSize = sizeof(int)*NUM_DATA;\n",
        "\tprintf(\"%d elements, memSize = %d bytes\\n\", NUM_DATA, memSize);\n",
        "\n",
        "\t// Memory allocation on the host-side\n",
        "\ta = new int[NUM_DATA]; memset(a, 0, memSize);\n",
        "\tb = new int[NUM_DATA]; memset(b, 0, memSize);\n",
        "\tc = new int[NUM_DATA]; memset(c, 0, memSize);\n",
        "\n",
        "\t// Data generation\n",
        "\tfor (int i = 0; i < NUM_DATA; i++) {\n",
        "\t\ta[i] = rand() % 10;\n",
        "\t\tb[i] = rand() % 10;\n",
        "\t}\n",
        "\n",
        "\t// Memory allocation on the device-side\n",
        "\tcudaMalloc(&d_a, memSize);\n",
        "\tcudaMalloc(&d_b, memSize);\n",
        "\tcudaMalloc(&d_c, memSize);\n",
        "\n",
        "\t// Data copy : Host -> Device\n",
        "\n",
        "\tcudaMemcpy(d_a, a, memSize, cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(d_b, b, memSize, cudaMemcpyHostToDevice);\n",
        "\n",
        "\t// Kernel call\n",
        "\tvecAdd<<<1, NUM_DATA >>>(d_a, d_b, d_c);\n",
        "\n",
        "\t// Copy results : Device -> Host\n",
        "\tcudaMemcpy(c, d_c, memSize, cudaMemcpyDeviceToHost);\n",
        "\n",
        "\t// Check results\n",
        "\tbool result = true;\n",
        "\tfor (int i = 0; i < NUM_DATA; i++) {\n",
        "\t\tif (a[i] + b[i] != c[i]) {\n",
        "\t\t\tprintf(\"[%d] The resutls is not matched! (%d, %d)\\n\"\n",
        "\t\t\t\t, i, a[i] + b[i], c[i]);\n",
        "\t\t\tresult = false;\n",
        "\t\t}\n",
        "\t}\n",
        "\n",
        "\tif (result)\n",
        "\t\tprintf(\"GPU works well!\\n\");\n",
        "\n",
        "\t// Release device memory\n",
        "\tcudaFree(d_a); cudaFree(d_b); cudaFree(d_c);\n",
        "\t// Release host memory\n",
        "\tdelete[] a; delete[] b; delete[] c;\n",
        "\n",
        "\treturn 0;\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "512 elements, memSize = 2048 bytes\n",
            "GPU works well!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecAe7QFle7gP"
      },
      "source": [
        "DS Timer 다운받기\n",
        "1. 다운받은 파일 usr/local/include 에 넣기\n",
        "2. DS_Timer.cpp에 있는 거 없애고 .h에 다 넣기 (undefiend reference to - Error 발생)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbf9kH55Pwt9",
        "outputId": "a521108e-dfc3-479d-9fe0-40b5df16f2dc"
      },
      "source": [
        "!git clone https://gitlab.com/DuksuKim/multi-core-programming-.-cph351-koreatech.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'multi-core-programming-.-cph351-koreatech'...\n",
            "remote: Enumerating objects: 531, done.\u001b[K\n",
            "remote: Counting objects: 100% (188/188), done.\u001b[K\n",
            "remote: Compressing objects: 100% (114/114), done.\u001b[K\n",
            "remote: Total 531 (delta 104), reused 150 (delta 73), pack-reused 343\u001b[K\n",
            "Receiving objects: 100% (531/531), 745.41 KiB | 11.47 MiB/s, done.\n",
            "Resolving deltas: 100% (302/302), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5WTHHFKfDsy"
      },
      "source": [
        "# .cu 파일 작성 예시"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ayWM4xG6XA5C",
        "outputId": "fa2db565-ecd3-4af1-ee82-aa3513c57ea4"
      },
      "source": [
        "%%cuda --name my_curand.cu \n",
        "/*\n",
        " * This program uses the host CURAND API to generate 100 \n",
        " * pseudorandom floats.\n",
        " */\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#include <curand.h>\n",
        "\n",
        "#define CUDA_CALL(x) do { if((x)!=cudaSuccess) { \\\n",
        "    printf(\"Error at %s:%d\\n\",__FILE__,__LINE__);\\\n",
        "    return EXIT_FAILURE;}} while(0)\n",
        "#define CURAND_CALL(x) do { if((x)!=CURAND_STATUS_SUCCESS) { \\\n",
        "    printf(\"Error at %s:%d\\n\",__FILE__,__LINE__);\\\n",
        "    return EXIT_FAILURE;}} while(0)\n",
        "\n",
        "int main(int argc, char *argv[])\n",
        "{\n",
        "    size_t n = 100;\n",
        "    size_t i;\n",
        "    curandGenerator_t gen;\n",
        "    float *devData, *hostData;\n",
        "\n",
        "    /* Allocate n floats on host */\n",
        "    hostData = (float *)calloc(n, sizeof(float));\n",
        "\n",
        "    /* Allocate n floats on device */\n",
        "    CUDA_CALL(cudaMalloc((void **)&devData, n*sizeof(float)));\n",
        "\n",
        "    /* Create pseudo-random number generator */\n",
        "    CURAND_CALL(curandCreateGenerator(&gen, \n",
        "                CURAND_RNG_PSEUDO_DEFAULT));\n",
        "\n",
        "    /* Set seed */\n",
        "    CURAND_CALL(curandSetPseudoRandomGeneratorSeed(gen, \n",
        "                1234ULL));\n",
        "\n",
        "    /* Generate n floats on device */\n",
        "    CURAND_CALL(curandGenerateUniform(gen, devData, n));\n",
        "\n",
        "    /* Copy device memory to host */\n",
        "    CUDA_CALL(cudaMemcpy(hostData, devData, n * sizeof(float),\n",
        "        cudaMemcpyDeviceToHost));\n",
        "\n",
        "    /* Show result */\n",
        "    for(i = 0; i < n; i++) {\n",
        "        printf(\"%1.4f \", hostData[i]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    /* Cleanup */\n",
        "    CURAND_CALL(curandDestroyGenerator(gen));\n",
        "    CUDA_CALL(cudaFree(devData));\n",
        "    free(hostData);    \n",
        "    return EXIT_SUCCESS;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'File written in /content/src/my_curand.cu'"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXRCHXMsfPUm"
      },
      "source": [
        "cu 컴파일"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lw-Azf-XXKOe"
      },
      "source": [
        "!nvcc -o /content/src/my_curand /content/src/my_curand.cu -lcurand"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8sO-Q4ZfUlD"
      },
      "source": [
        "만든 파일 실행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Klm8yS7vXMcv",
        "outputId": "0a8ff17b-afe5-426e-9dc0-559303c649f1"
      },
      "source": [
        "!/content/src/my_curand"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1455 0.8202 0.5504 0.2948 0.9147 0.8690 0.3219 0.7829 0.0113 0.2855 0.7816 0.2338 0.6791 0.2824 0.6299 0.1212 0.4333 0.3831 0.5136 0.2987 0.4166 0.0345 0.0494 0.0467 0.6166 0.6480 0.8685 0.4012 0.0631 0.4972 0.6809 0.9350 0.0704 0.0458 0.1324 0.3785 0.6457 0.9930 0.9952 0.7677 0.3217 0.8210 0.2765 0.2691 0.4579 0.1969 0.9555 0.8739 0.7996 0.3810 0.6662 0.3153 0.9428 0.5006 0.3369 0.1490 0.8637 0.6191 0.6820 0.4573 0.9261 0.5650 0.7117 0.8252 0.8755 0.2216 0.2958 0.4046 0.3896 0.7335 0.7301 0.8154 0.0913 0.0866 0.6974 0.1811 0.5834 0.9255 0.9029 0.0413 0.9522 0.5507 0.7237 0.3976 0.7519 0.4398 0.4638 0.6094 0.7358 0.3272 0.6961 0.4893 0.9698 0.0456 0.2025 0.9491 0.1516 0.0424 0.6149 0.5638 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LrVfrPBfayF"
      },
      "source": [
        "# Vector Sum 예제"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AiNa-3bTO78A",
        "outputId": "f691f6c5-1aa1-42d8-a22c-95c4ff952986"
      },
      "source": [
        "%%cuda --name vectorsum.cu\n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"device_launch_parameters.h\"\n",
        "\n",
        "#include \"DS_timer.h\"\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <string.h>\n",
        "\n",
        "// The size of the vector\n",
        "#define NUM_DATA 10240\n",
        "\n",
        "// Simple vector sum kernel (Max vector size : 1024)\n",
        "__global__ void vecAdd(int *_a, int *_b, int *_c) {\n",
        "\tint tID = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "\t_c[tID] = _a[tID] + _b[tID];\n",
        "}\n",
        "\n",
        "\n",
        "int main(void)\n",
        "{\n",
        "\t// Set timer\n",
        "\tDS_timer timer(5);\n",
        "\ttimer.setTimerName(0, \"CUDA Total\");\n",
        "\ttimer.setTimerName(1, \"Computation(Kernel)\");\n",
        "\ttimer.setTimerName(2, \"Data Trans. : Host -> Device\");\n",
        "\ttimer.setTimerName(3, \"Data Trans. : Device -> Host\");\n",
        "\ttimer.setTimerName(4, \"VectorSum on Host\");\n",
        "\ttimer.initTimers();\n",
        "\t//timer.timerOff();\n",
        "\n",
        "\tint *a, *b, *c, *h_c;\t// Vectors on the host\n",
        "\tint *d_a, *d_b, *d_c;\t// Vectors on the device\n",
        "\n",
        "\tint memSize = sizeof(int)*NUM_DATA;\n",
        "\tprintf(\"%d elements, memSize = %d bytes\\n\", NUM_DATA, memSize);\n",
        "\n",
        "\t// Memory allocation on the host-side\n",
        "\ta = new int[NUM_DATA]; memset(a, 0, memSize);\n",
        "\tb = new int[NUM_DATA]; memset(b, 0, memSize);\n",
        "\tc = new int[NUM_DATA]; memset(c, 0, memSize);\n",
        "\th_c = new int[NUM_DATA]; memset(h_c, 0, memSize);\n",
        "\n",
        "\t// Data generation\n",
        "\tfor (int i = 0; i < NUM_DATA; i++) {\n",
        "\t\ta[i] = rand() % 10;\n",
        "\t\tb[i] = rand() % 10;\n",
        "\t}\n",
        "\n",
        "\t// Vector sum on host (for performance comparision)\n",
        "\ttimer.onTimer(4);\n",
        "\tfor (int i = 0; i < NUM_DATA; i++)\n",
        "\t\th_c[i] = a[i] + b[i];\n",
        "\ttimer.offTimer(4);\n",
        "\n",
        "\t// Memory allocation on the device-side\n",
        "\tcudaMalloc(&d_a, memSize);\n",
        "\tcudaMalloc(&d_b, memSize);\n",
        "\tcudaMalloc(&d_c, memSize);\n",
        "\n",
        "\ttimer.onTimer(0);\n",
        "\n",
        "\t// Data copy : Host -> Device\n",
        "\ttimer.onTimer(2);\n",
        "\tcudaMemcpy(d_a, a, memSize, cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(d_b, b, memSize, cudaMemcpyHostToDevice);\n",
        "\ttimer.offTimer(2);\n",
        "\n",
        "\t// Kernel call\n",
        "\ttimer.onTimer(1);\n",
        "\n",
        "  dim3 gridSize(NUM_DATA/256,1,1);\n",
        "  dim3 blockSize(256,1,1);\n",
        "  vecAdd<<<gridSize, blockSize>>>(d_a,d_b,d_c);\n",
        "\n",
        "\t\n",
        "\tcudaDeviceSynchronize(); // synchronization function\n",
        "\ttimer.offTimer(1);\n",
        "\n",
        "\t// Copy results : Device -> Host\n",
        "\ttimer.onTimer(3);\n",
        "\tcudaMemcpy(c, d_c, memSize, cudaMemcpyDeviceToHost);\n",
        "\ttimer.offTimer(3);\n",
        "\n",
        "\ttimer.offTimer(0); timer.printTimer();\n",
        "\n",
        "\t// Check results\n",
        "\tbool result = true;\n",
        "\tfor (int i = 0; i < NUM_DATA; i++) {\n",
        "\t\tif (h_c[i] != c[i]) {\n",
        "\t\t\tprintf(\"[%d] The resutls is not matched! (%d, %d)\\n\"\n",
        "\t\t\t\t, i, h_c[i], c[i]);\n",
        "\t\t\tresult = false;\n",
        "\t\t}\n",
        "\t}\n",
        "\n",
        "\tif (result)\n",
        "\t\tprintf(\"GPU works well!\\n\");\n",
        "\n",
        "\t// Release device memory\n",
        "\tcudaFree(d_a); cudaFree(d_b); cudaFree(d_c);\n",
        "\t// Release host memory\n",
        "\tdelete[] a; delete[] b; delete[] c;\n",
        "\n",
        "\treturn 0;\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'File written in /content/src/vectorsum.cu'"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwZjO4JPX-Ib",
        "outputId": "8011c430-019a-44c9-e593-23581be101c5"
      },
      "source": [
        "!nvcc -o /content/src/vectorsum /content/src/vectorsum.cu -lcurand"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/src/vectorsum.cu(24): warning: conversion from a string literal to \"char *\" is deprecated\n",
            "\n",
            "/content/src/vectorsum.cu(25): warning: conversion from a string literal to \"char *\" is deprecated\n",
            "\n",
            "/content/src/vectorsum.cu(26): warning: conversion from a string literal to \"char *\" is deprecated\n",
            "\n",
            "/content/src/vectorsum.cu(27): warning: conversion from a string literal to \"char *\" is deprecated\n",
            "\n",
            "/content/src/vectorsum.cu(28): warning: conversion from a string literal to \"char *\" is deprecated\n",
            "\n",
            "/content/src/vectorsum.cu(24): warning: conversion from a string literal to \"char *\" is deprecated\n",
            "\n",
            "/content/src/vectorsum.cu(25): warning: conversion from a string literal to \"char *\" is deprecated\n",
            "\n",
            "/content/src/vectorsum.cu(26): warning: conversion from a string literal to \"char *\" is deprecated\n",
            "\n",
            "/content/src/vectorsum.cu(27): warning: conversion from a string literal to \"char *\" is deprecated\n",
            "\n",
            "/content/src/vectorsum.cu(28): warning: conversion from a string literal to \"char *\" is deprecated\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHpx2EtAZeBC",
        "outputId": "591dcdff-4e7a-43c6-f887-26cb1a76086e"
      },
      "source": [
        "!/content/src/vectorsum"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10240 elements, memSize = 40960 bytes\n",
            "\n",
            "*\t DS_timer Report \t*\n",
            "* The number of timer = 5, counter = 5\n",
            "**** Timer report ****\n",
            "CUDA Total : 0.23900 ms (0.23900 ms)\n",
            "Computation(Kernel) : 0.13000 ms (0.13000 ms)\n",
            "Data Trans. : Host -> Device : 0.07800 ms (0.07800 ms)\n",
            "Data Trans. : Device -> Host : 0.03100 ms (0.03100 ms)\n",
            "VectorSum on Host : 0.03200 ms (0.03200 ms)\n",
            "**** Counter report ****\n",
            "*\t End of the report \t*\n",
            "GPU works well!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDaz0u_xBv4R"
      },
      "source": [
        "# Matrix Multiply_Single 예제"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-TXPa13g233t",
        "outputId": "22a1925c-96f7-4094-f5e9-8651eec1f4b2"
      },
      "source": [
        "%%cuda --name MatrixMultiply.cu\n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"device_launch_parameters.h\"\n",
        "\n",
        "#include <DS_timer.h>\n",
        "\n",
        "#include <omp.h>\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <string.h>\n",
        "\n",
        "#define NUM_CPU_THREADS 4\n",
        "\n",
        "#define ROW_SIZE 32\n",
        "#define K_SIZE 128\n",
        "#define COL_SIZE 32\n",
        "\n",
        "#define WORK_LOAD  1024\n",
        "#define WORK_LOAD2  100\n",
        "#define MAT_SIZE_A ROW_SIZE*K_SIZE\n",
        "#define MAT_SIZE_B K_SIZE*COL_SIZE\n",
        "#define MAT_SIZE_C ROW_SIZE*COL_SIZE\n",
        "\n",
        "// input matrix\n",
        "float A[ROW_SIZE][K_SIZE];     // m*k\n",
        "float B[K_SIZE][COL_SIZE];     // k*n\n",
        "\n",
        "// timer\n",
        "DS_timer* timer;\n",
        "#define TIMER_HOST\t\t0\n",
        "#define TIMER_KERNEL\t1\n",
        "#define TIMER_KERNEL_NC\t2\n",
        "#define TIMER_KERNEL_SH\t3\n",
        "#define TIMER_KERNEL_SH_BC\t4\n",
        "#define TIMER_HtoD\t\t5\n",
        "#define TIMER_DtoH\t\t6\n",
        "#define NUM_TIMER\t\t(TIMER_DtoH+1)\n",
        "\n",
        "void setTimer(void);\n",
        "void genInputMatrix(void);\n",
        "\n",
        "// output matrix\n",
        "float hostC[ROW_SIZE][COL_SIZE];\n",
        "float deviceC[COL_SIZE][COL_SIZE];\n",
        "\n",
        "#define memsetZero(_P,_type,_size) memset(_P, 0, sizeof(_type)*_size);\n",
        "#define dMemAlloc(_P, _type, _size) cudaMalloc(&_P, sizeof(_type)*_size);\n",
        "\n",
        "__global__ void matMul_kernel(float* _A, float* _B, float* _C){\n",
        "    int row = threadIdx.y;\n",
        "    int col = threadIdx.x;\n",
        "    int index = row*blockDim.x + col;\n",
        "\n",
        "    _C[index] = 0;\n",
        "    for(int k=0;k<K_SIZE;k++)\n",
        "        for(int i=0;i<WORK_LOAD;i++)\n",
        "            for(int j=0;j<WORK_LOAD2;j++)\n",
        "                _C[index] += _A[row*K_SIZE + k]*_B[k*COL_SIZE + col];\n",
        "}\n",
        "\n",
        "__global__ void matMul_kernel_NC(float* _A, float* _B, float* _C){\n",
        "    int row = threadIdx.x;\n",
        "    int col = threadIdx.y;\n",
        "    int index = row*blockDim.y + col;\n",
        "\n",
        "    _C[index] = 0;\n",
        "    for(int k=0;k<K_SIZE;k++)\n",
        "        for(int i=0;i<WORK_LOAD;i++)\n",
        "            for(int j=0;j<WORK_LOAD2;j++)\n",
        "                _C[index] += _A[row*K_SIZE + k]*_B[k*COL_SIZE + col];\n",
        "}\n",
        "\n",
        "__global__ void matMul_kernel_shared(float* _A, float* _B, float* _C){\n",
        "    int row = threadIdx.y;\n",
        "    int col = threadIdx.x;\n",
        "    int index = row*blockDim.x + col;\n",
        "\n",
        "    __shared__ float sharedA[ROW_SIZE][K_SIZE]; // Shared Memory에 공간 잡기\n",
        "    __shared__ float sharedB[K_SIZE][COL_SIZE];\n",
        "\n",
        "    for(int k=0;k<K_SIZE;k++){\n",
        "        sharedA[row][k] = _A[row*K_SIZE + k];\n",
        "        sharedB[k][col] = _B[k*COL_SIZE + col];\n",
        "    }\n",
        "    __syncthreads(); // Shared Memory에 모든 값이 다 올라갈 때 까지 기다림 \n",
        "\n",
        "    _C[index] = 0;\n",
        "    for(int k=0;k<K_SIZE;k++)\n",
        "        for(int i=0;i<WORK_LOAD;i++)\n",
        "            for(int j=0;j<WORK_LOAD2;j++)\n",
        "                _C[index] += sharedA[row][k] * sharedB[k][col];\n",
        "}\n",
        "\n",
        "__global__ void matMul_kernel_shared_BC(float* _A, float* _B, float* _C){\n",
        "    int row = threadIdx.x;\n",
        "    int col = threadIdx.y;\n",
        "    int index = row*blockDim.y + col;\n",
        "\n",
        "    __shared__ float sharedA[ROW_SIZE][K_SIZE]; // Shared Memory에 공간 잡기\n",
        "    __shared__ float sharedB[K_SIZE][COL_SIZE];\n",
        "\n",
        "    for(int k=0;k<K_SIZE;k++){\n",
        "        sharedA[row][k] = _A[row*K_SIZE + k];\n",
        "        sharedB[k][col] = _B[k*COL_SIZE + col];\n",
        "    }\n",
        "    __syncthreads(); // Shared Memory에 모든 값이 다 올라갈 때 까지 기다림 \n",
        "\n",
        "    _C[index] = 0;\n",
        "    for(int k=0;k<K_SIZE;k++)\n",
        "        for(int i=0;i<WORK_LOAD;i++)\n",
        "            for(int j=0;j<WORK_LOAD2;j++)\n",
        "                _C[index] += sharedA[row][k] * sharedB[k][col];\n",
        "}\n",
        "\n",
        "int main(void){\n",
        "    timer = NULL; setTimer();\n",
        "    float *dA, *dB, *dC; \n",
        "    dA= dB = dC = NULL;\n",
        "    \n",
        "    memsetZero(A,float,MAT_SIZE_A); memsetZero(B,float,MAT_SIZE_B);\n",
        "    memsetZero(hostC,float,MAT_SIZE_C); memsetZero(deviceC,float,MAT_SIZE_C);\n",
        "\n",
        "    // device(GPU) memory Allocation\n",
        "    dMemAlloc(dA,float,MAT_SIZE_A);\n",
        "    dMemAlloc(dB,float,MAT_SIZE_B);\n",
        "    dMemAlloc(dC,float,MAT_SIZE_C);\n",
        "\n",
        "    genInputMatrix();\n",
        "\n",
        "    //Host Code\n",
        "    timer->onTimer(TIMER_HOST);\n",
        "    for(int r=0;r<ROW_SIZE;r++)\n",
        "        for(int c=0;c<COL_SIZE;c++)\n",
        "            for(int k=0;k<K_SIZE;k++)\n",
        "                for(int i=0;i<WORK_LOAD;i++)\n",
        "                    for(int j=0;j<WORK_LOAD2;j++)\n",
        "                        hostC[r][c] += A[r][k] * B[k][c];\n",
        "    timer->offTimer(TIMER_HOST);\n",
        "    // ------------------------ Device(GPU)-------------------------//\n",
        "    //Copy input matrics : Host To Device (CPU > GPU)\n",
        "    timer->onTimer(TIMER_HtoD);\n",
        "    cudaMemcpy(dA,A,sizeof(float)*MAT_SIZE_A,cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(dB,B,sizeof(float)*MAT_SIZE_B,cudaMemcpyHostToDevice);\n",
        "    timer->offTimer(TIMER_HtoD);\n",
        "\n",
        "    dim3 blockDim(COL_SIZE,ROW_SIZE);     // 2D Block Dimension\n",
        "    dim3 blockDim_NC(ROW_SIZE,COL_SIZE);  // 2D Block Dimension Not Coalesced\n",
        "    \n",
        "    // Mat Multiply kernel call\n",
        "    timer->onTimer(TIMER_KERNEL);\n",
        "    matMul_kernel <<<1,blockDim>>> (dA,dB,dC);\n",
        "    cudaThreadSynchronize();\n",
        "    timer->offTimer(TIMER_KERNEL);\n",
        "\n",
        "    // Mat Multiply Not Coalesced kernel call\n",
        "    timer->onTimer(TIMER_KERNEL_NC);\n",
        "    matMul_kernel_NC <<<1,blockDim_NC>>> (dA,dB,dC);\n",
        "    cudaThreadSynchronize();\n",
        "    timer->offTimer(TIMER_KERNEL_NC);\n",
        "\n",
        "    // Shared Mem Mat Multiply kernel call\n",
        "    timer->onTimer(TIMER_KERNEL_SH);\n",
        "    matMul_kernel_shared <<<1,blockDim>>> (dA,dB,dC);\n",
        "    cudaThreadSynchronize();\n",
        "    timer->offTimer(TIMER_KERNEL_SH);\n",
        "\n",
        "    // Shared Mem Mat Multiply kernel call has Bank Conflict\n",
        "    timer->onTimer(TIMER_KERNEL_SH_BC);\n",
        "    matMul_kernel_shared_BC <<<1,blockDim_NC>>> (dA,dB,dC);\n",
        "    cudaThreadSynchronize();\n",
        "    timer->offTimer(TIMER_KERNEL_SH_BC);\n",
        "\n",
        "    // Get Result From Device : Device To Host (GPU > CPU)\n",
        "    timer->onTimer(TIMER_DtoH);\n",
        "    cudaMemcpy(deviceC,dC,sizeof(float)*MAT_SIZE_C,cudaMemcpyDeviceToHost);\n",
        "    timer->offTimer(TIMER_DtoH);\n",
        "\n",
        "    // Check Result \n",
        "    bool isSame = true;\n",
        "\n",
        "    float *pHostC = &hostC[0][0];\n",
        "    float *pDeviceC = &deviceC[0][0];\n",
        "\n",
        "    for(int i=0;i<MAT_SIZE_C;i++){\n",
        "        if(pHostC[i] != pDeviceC[i]){\n",
        "            printf(\"[%d] %.2f, %.2f\\n\", i, pHostC[i],pDeviceC[i]);\n",
        "            isSame = false;\n",
        "            break;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    if(isSame) printf(\"Result is Same On CPU & GPU! \\n\");\n",
        "    else printf(\"Result is Different on CPU & GPU. Something is Wrong! \\n\");\n",
        "\n",
        "    timer->printTimer();\n",
        "    if(timer != NULL)\n",
        "        delete timer;\n",
        "}\n",
        "\n",
        "void genInputMatrix(void){\n",
        "    for(int r=0;r<ROW_SIZE;r++)\n",
        "        for(int k=0;k<K_SIZE;k++)\n",
        "            A[r][k] = rand() % 100;\n",
        "    \n",
        "    for(int k=0;k<K_SIZE;k++)\n",
        "        for(int c=0;c<COL_SIZE;c++)\n",
        "            B[k][c] = rand() % 100;\n",
        "}\n",
        "\n",
        "void setTimer(void){\n",
        "    timer = new DS_timer(NUM_TIMER);\n",
        "\n",
        "    timer->initTimers();\n",
        "    timer->setTimerName(TIMER_HOST,\" CPU code                    \");\n",
        "    timer->setTimerName(TIMER_KERNEL,\" Kernel launch(Coalasced)    \");\n",
        "    timer->setTimerName(TIMER_KERNEL_NC,\" Kernel launch(Not Coalasced)\");\n",
        "    timer->setTimerName(TIMER_KERNEL_SH,\" Kernel launch (shared ver.) \");\n",
        "    timer->setTimerName(TIMER_KERNEL_SH_BC,\"Kernel launch (shared ver)BC \");\n",
        "    timer->setTimerName(TIMER_HtoD,\"[Data Transfer] Host > Device\");\n",
        "    timer->setTimerName(TIMER_DtoH,\"[Data Transfer] Device > Host\");\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'File written in /content/src/MatrixMultiply.cu'"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekyq5edF5VHc",
        "outputId": "db38a5af-6065-46b9-b7ab-56d00a08889f"
      },
      "source": [
        "!nvcc -o /content/src/MatrixMultiply /content/src/MatrixMultiply.cu -lcurand"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/src/MatrixMultiply.cu(213): warning: conversion from a string literal to \"char *\" is deprecated\n",
            "\n",
            "/content/src/MatrixMultiply.cu(214): warning: conversion from a string literal to \"char *\" is deprecated\n",
            "\n",
            "/content/src/MatrixMultiply.cu(215): warning: conversion from a string literal to \"char *\" is deprecated\n",
            "\n",
            "/content/src/MatrixMultiply.cu(216): warning: conversion from a string literal to \"char *\" is deprecated\n",
            "\n",
            "/content/src/MatrixMultiply.cu(217): warning: conversion from a string literal to \"char *\" is deprecated\n",
            "\n",
            "/content/src/MatrixMultiply.cu(218): warning: conversion from a string literal to \"char *\" is deprecated\n",
            "\n",
            "/content/src/MatrixMultiply.cu(219): warning: conversion from a string literal to \"char *\" is deprecated\n",
            "\n",
            "/content/src/MatrixMultiply.cu(213): warning: conversion from a string literal to \"char *\" is deprecated\n",
            "\n",
            "/content/src/MatrixMultiply.cu(214): warning: conversion from a string literal to \"char *\" is deprecated\n",
            "\n",
            "/content/src/MatrixMultiply.cu(215): warning: conversion from a string literal to \"char *\" is deprecated\n",
            "\n",
            "/content/src/MatrixMultiply.cu(216): warning: conversion from a string literal to \"char *\" is deprecated\n",
            "\n",
            "/content/src/MatrixMultiply.cu(217): warning: conversion from a string literal to \"char *\" is deprecated\n",
            "\n",
            "/content/src/MatrixMultiply.cu(218): warning: conversion from a string literal to \"char *\" is deprecated\n",
            "\n",
            "/content/src/MatrixMultiply.cu(219): warning: conversion from a string literal to \"char *\" is deprecated\n",
            "\n",
            "\u001b[01m\u001b[K/content/src/MatrixMultiply.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kint main()\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/src/MatrixMultiply.cu:151:23:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KcudaError_t cudaThreadSynchronize()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     cudaThreadSynchron\u001b[01;35m\u001b[Ki\u001b[m\u001b[Kze();\n",
            "                       \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cuda_runtime_api.h:957:46:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " extern __CUDA_DEPRECATED __host__ cudaError_t\u001b[01;36m\u001b[K CUDARTAPI cudaThread\u001b[m\u001b[KSynchronize(void);\n",
            "                                              \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/src/MatrixMultiply.cu:157:23:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KcudaError_t cudaThreadSynchronize()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     cudaThreadSynchron\u001b[01;35m\u001b[Ki\u001b[m\u001b[Kze();\n",
            "                       \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cuda_runtime_api.h:957:46:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " extern __CUDA_DEPRECATED __host__ cudaError_t\u001b[01;36m\u001b[K CUDARTAPI cudaThread\u001b[m\u001b[KSynchronize(void);\n",
            "                                              \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/src/MatrixMultiply.cu:163:23:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KcudaError_t cudaThreadSynchronize()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     cudaThreadSynchron\u001b[01;35m\u001b[Ki\u001b[m\u001b[Kze();\n",
            "                       \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cuda_runtime_api.h:957:46:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " extern __CUDA_DEPRECATED __host__ cudaError_t\u001b[01;36m\u001b[K CUDARTAPI cudaThread\u001b[m\u001b[KSynchronize(void);\n",
            "                                              \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/src/MatrixMultiply.cu:169:23:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KcudaError_t cudaThreadSynchronize()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     cudaThreadSynchron\u001b[01;35m\u001b[Ki\u001b[m\u001b[Kze();\n",
            "                       \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cuda_runtime_api.h:957:46:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " extern __CUDA_DEPRECATED __host__ cudaError_t\u001b[01;36m\u001b[K CUDARTAPI cudaThread\u001b[m\u001b[KSynchronize(void);\n",
            "                                              \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoPynElE8aUl",
        "outputId": "ae31c9b4-2f25-4d21-8190-39eb5fcf790f"
      },
      "source": [
        "!/content/src/MatrixMultiply"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result is Same On CPU & GPU! \n",
            "\n",
            "*\t DS_timer Report \t*\n",
            "* The number of timer = 7, counter = 7\n",
            "**** Timer report ****\n",
            " CPU code                     : 57163.31900 ms (57163.31900 ms)\n",
            " Kernel launch(Coalasced)     : 3950.27400 ms (3950.27400 ms)\n",
            " Kernel launch(Not Coalasced) : 52928.72900 ms (52928.72900 ms)\n",
            " Kernel launch (shared ver.)  : 141.90300 ms (141.90300 ms)\n",
            "Kernel launch (shared ver)BC  : 142.19600 ms (142.19600 ms)\n",
            "[Data Transfer] Host > Device : 0.08900 ms (0.08900 ms)\n",
            "[Data Transfer] Device > Host : 0.12600 ms (0.12600 ms)\n",
            "**** Counter report ****\n",
            "*\t End of the report \t*\n"
          ]
        }
      ]
    }
  ]
}